{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d58f1e00",
   "metadata": {},
   "source": [
    "## Key Features:\n",
    "1. recursive_chunk_text() - Main method for chunking raw text strings\n",
    "2. recursive_chunk_documents() - Method for chunking existing Document objects\n",
    "3. chunk_with_metadata() - Method that preserves metadata across chunks\n",
    "\n",
    "### How Recursive Chunking Works:\n",
    "The RecursiveCharacterTextSplitter uses a hierarchy of separators:\n",
    "1. First tries to split on \\n\\n (paragraph breaks)\n",
    "2. Then tries \\n (line breaks)\n",
    "3. Then tries (spaces)\n",
    "4. Finally splits on any character if needed\n",
    "This approach helps preserve semantic boundaries while ensuring chunks don't exceed the specified size."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6af36dea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Basic Recursive Chunking ===\n",
      "Number of chunks: 6\n",
      "\n",
      "Chunk 1:\n",
      "Length: 63\n",
      "Content: This is a sample document that demonstrates recursive chunking....\n",
      "\n",
      "Chunk 2:\n",
      "Length: 146\n",
      "Content: The first paragraph contains some initial information about the topic.\n",
      "        It explains the basic...\n",
      "\n",
      "Chunk 3:\n",
      "Length: 159\n",
      "Content: The second paragraph goes into more detail about the implementation.\n",
      "        It discusses the techni...\n",
      "\n",
      "Chunk 4:\n",
      "Length: 160\n",
      "Content: The third paragraph concludes the document with final thoughts and recommendations.\n",
      "        It summa...\n",
      "\n",
      "Chunk 5:\n",
      "Length: 173\n",
      "Content: This is additional content to make the text longer and demonstrate chunking behavior.\n",
      "        The re...\n",
      "\n",
      "Chunk 6:\n",
      "Length: 64\n",
      "Content: trying to preserve semantic boundaries and maintain readability....\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Recursive Chunking using LangChain\n",
    "\n",
    "This module provides methods for recursively splitting text into smaller chunks\n",
    "while preserving semantic boundaries using LangChain's text splitters.\n",
    "\"\"\"\n",
    "class file_chunking:\n",
    "    from typing import List, Optional, Dict, Any\n",
    "    from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "    from langchain.schema import Document\n",
    "\n",
    "\n",
    "    def recursive_chunk_text(\n",
    "        text: str,\n",
    "        chunk_size: int = 1000,\n",
    "        chunk_overlap: int = 200,\n",
    "        separators: Optional[List[str]] = None,\n",
    "        length_function: Optional[callable] = None,\n",
    "        is_separator_regex: bool = False,\n",
    "        keep_separator: bool = False,\n",
    "        add_start_index: bool = False,\n",
    "        strip_whitespace: bool = True,\n",
    "        **kwargs: Any\n",
    "    ) -> List[Document]:\n",
    "        \"\"\"\n",
    "        Recursively chunk text using LangChain's RecursiveCharacterTextSplitter.\n",
    "        \n",
    "        This method splits text into smaller chunks while trying to preserve\n",
    "        semantic boundaries by using a hierarchy of separators.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The input text to be chunked\n",
    "            chunk_size (int): The target size of each chunk in characters. Default: 1000\n",
    "            chunk_overlap (int): The number of characters to overlap between chunks. Default: 200\n",
    "            separators (List[str], optional): List of separators to use for splitting.\n",
    "                If None, uses default separators: [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "            length_function (callable, optional): Function to calculate length of text.\n",
    "                If None, uses len() function\n",
    "            is_separator_regex (bool): Whether separators are regex patterns. Default: False\n",
    "            keep_separator (bool): Whether to keep separators in the chunks. Default: False\n",
    "            add_start_index (bool): Whether to add start index to metadata. Default: False\n",
    "            strip_whitespace (bool): Whether to strip whitespace from chunks. Default: True\n",
    "            **kwargs: Additional arguments passed to RecursiveCharacterTextSplitter\n",
    "            \n",
    "        Returns:\n",
    "            List[Document]: List of Document objects containing the chunked text\n",
    "            \n",
    "        Example:\n",
    "            >>> text = \"This is a long text that needs to be chunked. \" * 100\n",
    "            >>> chunks = recursive_chunk_text(text, chunk_size=500, chunk_overlap=50)\n",
    "            >>> print(f\"Number of chunks: {len(chunks)}\")\n",
    "            >>> print(f\"First chunk: {chunks[0].page_content[:100]}...\")\n",
    "        \"\"\"\n",
    "        \n",
    "        # Set default separators if not provided\n",
    "        if separators is None:\n",
    "            separators = [\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        \n",
    "        # Set default length function if not provided\n",
    "        if length_function is None:\n",
    "            length_function = len\n",
    "        \n",
    "        # Create the recursive text splitter\n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=chunk_size,\n",
    "            chunk_overlap=chunk_overlap,\n",
    "            separators=separators,\n",
    "            length_function=length_function,\n",
    "            is_separator_regex=is_separator_regex,\n",
    "            keep_separator=keep_separator,\n",
    "            add_start_index=add_start_index,\n",
    "            strip_whitespace=strip_whitespace,\n",
    "            **kwargs\n",
    "        )\n",
    "        \n",
    "        # Split the text into chunks\n",
    "        chunks = text_splitter.split_text(text)\n",
    "        \n",
    "        # Convert to Document objects\n",
    "        documents = [Document(page_content=chunk) for chunk in chunks]\n",
    "        \n",
    "        return documents\n",
    "\n",
    "\n",
    "\n",
    "    # Example usage\n",
    "    if __name__ == \"__main__\":\n",
    "        # Example text for testing\n",
    "        sample_text = \"\"\"\n",
    "        This is a sample document that demonstrates recursive chunking.\n",
    "        \n",
    "        The first paragraph contains some initial information about the topic.\n",
    "        It explains the basic concepts and provides context for the reader.\n",
    "        \n",
    "        The second paragraph goes into more detail about the implementation.\n",
    "        It discusses the technical aspects and provides examples of how to use the method.\n",
    "        \n",
    "        The third paragraph concludes the document with final thoughts and recommendations.\n",
    "        It summarizes the key points and suggests next steps for the reader.\n",
    "        \n",
    "        This is additional content to make the text longer and demonstrate chunking behavior.\n",
    "        The recursive chunking algorithm will split this text into smaller pieces while\n",
    "        trying to preserve semantic boundaries and maintain readability.\n",
    "        \"\"\"\n",
    "        \n",
    "        # Test basic recursive chunking\n",
    "        print(\"=== Basic Recursive Chunking ===\")\n",
    "        chunks = recursive_chunk_text(sample_text, chunk_size=200, chunk_overlap=50)\n",
    "        print(f\"Number of chunks: {len(chunks)}\")\n",
    "        for i, chunk in enumerate(chunks):\n",
    "            print(f\"\\nChunk {i+1}:\")\n",
    "            print(f\"Length: {len(chunk.page_content)}\")\n",
    "            print(f\"Content: {chunk.page_content[:100]}...\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
