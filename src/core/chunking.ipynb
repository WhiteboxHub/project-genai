{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3f9b32b7",
   "metadata": {},
   "source": [
    "## Manual chunking\n",
    "Basic overlap chunking that supports:\n",
    "* Character-based or word-based chunking\n",
    "* Configurable chunk size and overlap size\n",
    "* Input validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "47ce4d75",
   "metadata": {},
   "outputs": [],
   "source": [
    "class file_chunking:\n",
    "    def manual_overlap_chunking(text, chunk_size, overlap_size, chunking_strategy=\"word\"):\n",
    "        \"\"\"\n",
    "        Manually chunk text with overlapping segments to preserve context.\n",
    "        \n",
    "        Args:\n",
    "            text (str): The input text to be chunked\n",
    "            chunk_size (int): The size of each chunk\n",
    "            overlap_size (int): The number of characters/words to overlap between chunks\n",
    "            chunking_strategy (str): Strategy for chunking - \"character\" or \"word\"\n",
    "        \n",
    "        Returns:\n",
    "            list: List of overlapping text chunks\n",
    "        \n",
    "        Raises:\n",
    "            ValueError: If chunk_size <= overlap_size or if invalid chunking_strategy\n",
    "        \"\"\"\n",
    "        if chunk_size <= overlap_size:\n",
    "            raise ValueError(\"chunk_size must be greater than overlap_size\")\n",
    "        \n",
    "        if chunking_strategy not in [\"word\"]:\n",
    "            raise ValueError(\"chunking_strategy must be 'word'\")\n",
    "        \n",
    "        if not text.strip():\n",
    "            return []\n",
    "        \n",
    "        chunks = []\n",
    "        \n",
    "    # Word split\n",
    "        words = text.split()\n",
    "        if len(words) == 0:\n",
    "            return []\n",
    "\n",
    "    # Manual chunking    \n",
    "        start = 0\n",
    "        while start < len(words):\n",
    "            end = min(start + chunk_size, len(words))\n",
    "            chunk = \" \".join(words[start:end])\n",
    "            chunks.append(chunk)\n",
    "            \n",
    "            # Move start position by (chunk_size - overlap_size)\n",
    "            start += chunk_size - overlap_size\n",
    "            \n",
    "            # Break if we've reached the end\n",
    "            if end == len(words):\n",
    "                break\n",
    "        \n",
    "        return chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9cf9aea7",
   "metadata": {},
   "outputs": [],
   "source": [
    "long_text = \"\"\"\n",
    "    Hugging Face provides tools for building, training, and deploying transformer-based models.\n",
    "    Chunking is useful for processing long documents that exceed the model’s max sequence length.\n",
    "    By splitting text into overlapping segments, we preserve context across chunks.\n",
    "    This technique is often used in NLP pipelines for retrieval-augmented generation (RAG),\n",
    "    question answering, and summarization.\n",
    "    \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "64ba2753",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Token-based ---\n",
      "Chunk 1: Hugging Face provides tools for building, training, and deploying transformer-based models. Chunking is useful for\n",
      "Chunk 2: is useful for processing long documents that exceed the model’s max sequence length. By splitting\n",
      "Chunk 3: length. By splitting text into overlapping segments, we preserve context across chunks. This technique is\n",
      "Chunk 4: This technique is often used in NLP pipelines for retrieval-augmented generation (RAG), question answering, and\n",
      "Chunk 5: question answering, and summarization.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Token-based ---\")\n",
    "token_chunks = manual_overlap_chunking(long_text, 15, 3, chunking_strategy=\"word\")\n",
    "for i, c in enumerate(token_chunks, 1):\n",
    "    print(f\"Chunk {i}: {c}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
