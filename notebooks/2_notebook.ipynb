{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1799a513",
   "metadata": {},
   "source": [
    "# DECODER ONLY MODELS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "170bdd58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting groq\n",
      "  Downloading groq-0.31.1-py3-none-any.whl.metadata (16 kB)\n",
      "Collecting anyio<5,>=3.5.0 (from groq)\n",
      "  Downloading anyio-4.10.0-py3-none-any.whl.metadata (4.0 kB)\n",
      "Collecting distro<2,>=1.7.0 (from groq)\n",
      "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
      "Collecting httpx<1,>=0.23.0 (from groq)\n",
      "  Downloading httpx-0.28.1-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting pydantic<3,>=1.9.0 (from groq)\n",
      "  Downloading pydantic-2.11.7-py3-none-any.whl.metadata (67 kB)\n",
      "Collecting sniffio (from groq)\n",
      "  Downloading sniffio-1.3.1-py3-none-any.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: typing-extensions<5,>=4.10 in /Users/harman/git_projects/project-genai/venv/lib/python3.13/site-packages (from groq) (4.15.0)\n",
      "Requirement already satisfied: idna>=2.8 in /Users/harman/git_projects/project-genai/venv/lib/python3.13/site-packages (from anyio<5,>=3.5.0->groq) (3.10)\n",
      "Requirement already satisfied: certifi in /Users/harman/git_projects/project-genai/venv/lib/python3.13/site-packages (from httpx<1,>=0.23.0->groq) (2025.8.3)\n",
      "Collecting httpcore==1.* (from httpx<1,>=0.23.0->groq)\n",
      "  Downloading httpcore-1.0.9-py3-none-any.whl.metadata (21 kB)\n",
      "Collecting h11>=0.16 (from httpcore==1.*->httpx<1,>=0.23.0->groq)\n",
      "  Downloading h11-0.16.0-py3-none-any.whl.metadata (8.3 kB)\n",
      "Collecting annotated-types>=0.6.0 (from pydantic<3,>=1.9.0->groq)\n",
      "  Downloading annotated_types-0.7.0-py3-none-any.whl.metadata (15 kB)\n",
      "Collecting pydantic-core==2.33.2 (from pydantic<3,>=1.9.0->groq)\n",
      "  Downloading pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
      "Collecting typing-inspection>=0.4.0 (from pydantic<3,>=1.9.0->groq)\n",
      "  Downloading typing_inspection-0.4.1-py3-none-any.whl.metadata (2.6 kB)\n",
      "Downloading groq-0.31.1-py3-none-any.whl (134 kB)\n",
      "Downloading anyio-4.10.0-py3-none-any.whl (107 kB)\n",
      "Downloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
      "Downloading httpx-0.28.1-py3-none-any.whl (73 kB)\n",
      "Downloading httpcore-1.0.9-py3-none-any.whl (78 kB)\n",
      "Downloading pydantic-2.11.7-py3-none-any.whl (444 kB)\n",
      "Downloading pydantic_core-2.33.2-cp313-cp313-macosx_11_0_arm64.whl (1.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.8/1.8 MB\u001b[0m \u001b[31m6.3 MB/s\u001b[0m  \u001b[33m0:00:00\u001b[0m eta \u001b[36m0:00:01\u001b[0m\n",
      "\u001b[?25hDownloading annotated_types-0.7.0-py3-none-any.whl (13 kB)\n",
      "Downloading h11-0.16.0-py3-none-any.whl (37 kB)\n",
      "Downloading sniffio-1.3.1-py3-none-any.whl (10 kB)\n",
      "Downloading typing_inspection-0.4.1-py3-none-any.whl (14 kB)\n",
      "Installing collected packages: typing-inspection, sniffio, pydantic-core, h11, distro, annotated-types, pydantic, httpcore, anyio, httpx, groq\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11/11\u001b[0m [groq]2m 7/11\u001b[0m [httpcore]\n",
      "\u001b[1A\u001b[2KSuccessfully installed annotated-types-0.7.0 anyio-4.10.0 distro-1.9.0 groq-0.31.1 h11-0.16.0 httpcore-1.0.9 httpx-0.28.1 pydantic-2.11.7 pydantic-core-2.33.2 sniffio-1.3.1 typing-inspection-0.4.1\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "315b5383",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from groq import Groq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "509002e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv(override=True) # This line loads the environment variables from the .env file\n",
    "\n",
    "# Now you can access the variables with os.getenv()\n",
    "groq_api_key = os.getenv(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fce5fdc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiate the Groq client\n",
    "client = Groq(\n",
    "    api_key=os.environ.get(\"GROQ_API_KEY\"),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "09782145",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to explain what encoder-only models are in five lines. Let's start by recalling what I know. Encoder-only models are types of neural networks used in NLP tasks. They focus on processing input data, like text, and creating representations that capture context. Unlike encoder-decoder models (like in transformers), they don't have a separate decoding part. Common examples are BERT and its variants. They're used for tasks like text classification or sentiment analysis. Hmm, I should make sure to mention the transformer architecture since they're based on that. Also, the self-attention mechanism is key here. I need to keep it concise, each line should be a separate point. Let me check the line count. Wait, five lines? Let me structure each line to cover the main aspects: definition, based on transformer encoders, self-attention, training with masks, and examples. Need to make sure each line is clear and flows logically. Maybe start with definition, then components, how they work, training method, and example models. That should cover it.\n",
      "</think>\n",
      "\n",
      "Encoder-only models are transformer-based architectures designed to process input sequences (e.g., text) without generating output sequences.  \n",
      "They rely on self-attention mechanisms to capture contextual relationships within the input, enabling rich semantic representations.  \n",
      "Pre-trained using tasks like masked language modeling, where tokens are predicted based on context.  \n",
      "Lack a decoding component, focusing instead on encoding inputs into fixed-dimensional embeddings.  \n",
      "Common examples include BERT, RoBERTa, and ALBERT, widely used for tasks like classification and question-answering.\n"
     ]
    }
   ],
   "source": [
    "# Define the messages for the chat completion\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": \"Explain in 5 lines encoder-only models.\",\n",
    "    },\n",
    "]\n",
    "\n",
    "# Create a completion request with the Qwen model\n",
    "completion = client.chat.completions.create(\n",
    "    model=\"qwen/qwen3-32b\",\n",
    "    messages=messages\n",
    ")\n",
    "\n",
    "# Print the model's response\n",
    "print(completion.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28ad8834",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a completion request with the Qwen model\n",
    "completion_llama = client.chat.completions.create(\n",
    "    model=\"openai/gpt-oss-120b\",\n",
    "    messages=messages\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "61005e9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "- Encoder‑only models consist solely of a stack of transformer encoders, without any decoder or generative head.  \n",
      "- They process the entire input sequence simultaneously, allowing each token to attend to all others via self‑attention.  \n",
      "- Pre‑training objectives (e.g., masked language modeling) teach the model to infer missing tokens from surrounding context.  \n",
      "- At inference, the learned contextual embeddings are used for downstream tasks such as classification, tagging, or retrieval.  \n",
      "- Examples include BERT, RoBERTa, ALBERT, and ELECTRA, which excel at understanding‑oriented NLP problems.\n"
     ]
    }
   ],
   "source": [
    "# Print the model's response\n",
    "print(completion_llama.choices[0].message.content)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
